{
  "models": {
    "llm": {
      "name": "GPT-3.5-Turbo",
      "version": "0.3.0",
      "framework": "openai",
      "type": "language",
      "status": "active"
    },
    "voice": {
      "name": "Bark",
      "version": "0.1.0", 
      "framework": "pytorch",
      "type": "audio",
      "status": "disabled"
    }
  },
  "creative_software_knowledge": {
    "photoshop": {
      "tools": {
        "count": 15,
        "categories": ["selection", "painting", "transformation", "repair", "vector"],
        "database": "embedded",
        "last_updated": "2024"
      },
      "workspaces": {
        "count": 8,
        "types": ["essentials", "photography", "painting", "design"],
        "customizable": true
      }
    },
    "blender": {
      "workspaces": {
        "count": 8,
        "types": ["modeling", "sculpting", "shading", "animation", "rendering"],
        "database": "embedded"
      },
      "tools": {
        "modeling_tools": 20,
        "sculpting_brushes": 15,
        "shading_nodes": 50
      }
    },
    "vegas_pro": {
      "tools": {
        "count": 12,
        "categories": ["editing", "effects", "audio", "color"],
        "database": "embedded"
      },
      "effects": {
        "video_fx": 200,
        "audio_fx": 50,
        "transitions": 30
      }
    }
  },
  "training": {
    "datasets": {
      "creative_software": {
        "sources": [
          "official_documentation",
          "community_tutorials", 
          "expert_knowledge"
        ],
        "size": "10MB",
        "format": "json",
        "last_updated": "2024"
      },
      "conversation": {
        "sources": ["synthetic_data", "user_interactions"],
        "size": "50MB",
        "format": "jsonl"
      }
    },
    "fine_tuning": {
      "enabled": false,
      "last_run": null,
      "epochs": 10,
      "learning_rate": 0.0001
    }
  },
  "model_paths": {
    "pretrained": "./models/pretrained/",
    "saved": "./models/saved/",
    "cache": "./models/cache/",
    "downloads": "./models/downloads/"
  },
  "memory_management": {
    "model_caching": true,
    "lazy_loading": true,
    "memory_limit": "4GB",
    "cleanup_interval": "1h"
  },
  "inference": {
    "batch_size": 1,
    "max_concurrent": 5,
    "timeout": 30,
    "retry_attempts": 3
  },
  "monitoring": {
    "performance_tracking": true,
    "error_logging": true,
    "usage_statistics": false,
    "model_health_checks": true
  }
} 